# Hyperpartisan News Detection Project

This repository contains the code and resources for a project focused on detecting hyperpartisan news articles using machine learning techniques, comparing traditional baseline models with a fine-tuned BERT model. This work was performed using data from the SemEval 2019 Task 4 competition.

## Overview

The project involves the following key steps:
1.  **Data Acquisition:** Downloading the official SemEval 2019 Task 4 dataset.
2.  **Data Parsing:** Processing the original XML files to extract text, labels, and publisher metadata into structured CSV files (`official_train_data.csv`, `official_test_data.csv`).
3.  **Exploratory Data Analysis (EDA):** Analyzing the training data to understand its characteristics and identify potential features differentiating hyperpartisan and non-hyperpartisan content.
4.  **Feature Engineering:** Creating numerical features (length, lexical, sentiment, TF-IDF, N-grams) from the text data for use with traditional machine learning models.
5.  **Baseline Model Training:** Training, evaluating, and tuning various baseline models (Logistic Regression, SVM, Random Forest, Gradient Boosting, Naive Bayes, Stacking Ensemble) using the engineered features.
6.  **Advanced Model Training (BERT):** Fine-tuning a pre-trained BERT Base model on the raw text data using 5-fold cross-validation and creating an ensemble for final evaluation.
7.  **Comparison:** Comparing the performance of the best baseline model against the BERT ensemble on the official test set.

## Repository Structure

```
.
├── hyperpartisan_data_official/ # Data downloaded/parsed here (Created by scripts)
│   ├── articles-training-byarticle-20181122/ # Extracted article XMLs (Train)
│   ├── articles-test-byarticle-20181207/   # Extracted article XMLs (Test)
│   ├── ground-truth-training-byarticle-20181122.xml
│   ├── ground-truth-test-byarticle-20181207.xml
│   ├── official_train_data.csv # Parsed training data
│   └── official_test_data.csv  # Parsed test data
│
├── hyperpartisan_features_official/ # Engineered features for baselines (Created by scripts)
│   ├── X_train_scaled.csv
│   ├── X_test_scaled.csv
│   ├── y_train.csv
│   ├── y_test.csv
│   ├── scaler.pkl
│   ├── tfidf_vectorizer.pkl
│   ├── bigram_vectorizer.pkl
│   └── feature_selector_tree.pkl # Or feature_selector_l1.pkl
│
├── hyperpartisan_models_official/ # Saved baseline models & plots (Created by scripts)
│   ├── logistic_regression.pkl
│   ├── random_forest_official_eval.png
│   ├── final_baseline_model.pkl 
│   └── ... # Other models and plots
│
├── hyperpartisan_bert_models/ # Saved BERT models & weights (Created by scripts)
│   └── bert_en_uncased_L-12_H-768_A-12_.../ # Directory for final ensemble weights
│       ├── fold_1_checkpoint_best.weights.h5
│       └── ... # Other fold weights
│
├── images/ # Plots generated by EDA notebook for the report
│   ├── eda_word_count_diversity.png
│   ├── eda_tfidf_diff_raw.png
│   └── ... # Other EDA plots
│
├── semeval_download.ipynb       # Notebook 1: Downloads and extracts SemEval data
├── xml_parse.ipynb              # Notebook 2: Parses XMLs into official CSV splits
├── data_analysis.ipynb          # Notebook 3: Performs EDA on official training data
├── feature_engineering.ipynb    # Notebook 4: Creates features for baseline models from official splits
├── model_training.ipynb         # Notebook 5: Trains and evaluates baseline models
├── BERT.py                      # Script 6: Trains and evaluates BERT model with CV/Ensemble
├── requirements.txt             # Python dependencies
└── README.md                    # This file
```

## Prerequisites

*   Python 3.10 or higher
*   `pip` package manager
*   Access to a machine with sufficient RAM (especially for data loading/processing) and ideally an NVIDIA GPU with CUDA support for training BERT efficiently (e.g., NVIDIA V100 32GB used for reported results).

## Setup

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/dlqnt/DAT550-Project
    cd DAT550-Project
    ```

2.  **Create and activate a virtual environment:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate  # On Linux/macOS
    # venv\Scripts\activate  # On Windows
    ```

3.  **Install dependencies:**
    ```bash
    pip install --upgrade pip
    pip install -r requirements.txt
    ```
    *(Note: You may need to install system libraries for `lxml` if XML parsing uses it and fails.)*

4.  **Download NLTK Data:** The notebooks will attempt to download necessary NLTK resources (`punkt`, `stopwords`, `vader_lexicon`). If this fails due to network restrictions, you may need to download them manually.

## Data Acquisition

The official SemEval 2019 Task 4 dataset is required. It is **not** included in this repository due to size.

1.  Run the `semeval_download.ipynb` notebook. This will download the necessary ZIP files from Zenodo and extract them into the `hyperpartisan_data_official/` directory.
    ```bash
    jupyter notebook semeval_download.ipynb 
    # Or run as a script: python -m ipykernel_launcher -f <connection_file> semeval_download.ipynb
    ```
    Verify that the `hyperpartisan_data_official` directory contains the extracted XML files and directories.

## Running the Experiments

Execute the notebooks/scripts **in the following order**:

1.  **`semeval_download.ipynb`**: Downloads and extracts the raw data (run only once).
2.  **`xml_parse.ipynb`**: Parses the raw XML data and creates `official_train_data.csv` and `official_test_data.csv` in the `hyperpartisan_data_official` directory.
3.  **`data_analysis.ipynb`**: Performs Exploratory Data Analysis on the official training data and saves plots to the `images/` directory.
4.  **`feature_engineering.ipynb`**: Reads the official CSV splits, engineers features for baseline models, performs scaling/vectorization (fitting only on train), and saves the processed feature matrices (`X_train_scaled.csv`, etc.) and fitted objects (`scaler.pkl`, etc.) to the `hyperpartisan_features_official/` directory.
5.  **`model_training.ipynb`**: Loads the engineered features, applies feature selection, trains various baseline models, performs hyperparameter tuning on the best one (SVM in our case), evaluates all models on the official test set features, and saves the models and evaluation plots to `hyperpartisan_models_official/`.
6.  **`BERT.py`**: Loads the official CSV splits, fine-tunes the BERT Base model using 5-fold cross-validation on the training data, saves the best weights for each fold, generates ensemble predictions on the official test set, evaluates the ensemble, and saves results/weights to `hyperpartisan_bert_models/...`.
    ```bash
    python BERT.py 
    ```
    *(Note: This script requires a capable GPU and may take a significant amount of time to run.)*

## Expected Results / Outputs

After running all steps:
*   The `hyperpartisan_data_official` directory will contain the downloaded/extracted data and the parsed `official_*.csv` files.
*   The `hyperpartisan_features_official` directory will contain the engineered features and saved scaler/vectorizers/selector.
*   The `hyperpartisan_models_official` directory will contain saved baseline models (`.pkl`) and their evaluation plots (`.png`).
*   The `hyperpartisan_bert_models` directory will contain saved weights for each BERT fold (`.weights.h5`).
*   The `images` directory will contain plots from the EDA.
*   The terminal output (or notebook cells) will display performance metrics (Accuracy, Precision, Recall, F1, AUC, Confusion Matrices) for all baseline models and the final BERT ensemble on the official test set. The results should closely match those presented in the project report.

## Environment Details

The results reported were obtained using the following environment (or similar):
*   Python: 3.10.x
*   TensorFlow: 2.12.0
*   Scikit-learn: [Specify Version, e.g., 1.2.2]
*   Pandas: [Specify Version, e.g., 2.0.3]
*   NLTK: [Specify Version, e.g., 3.8.1]
*   GPU: NVIDIA Tesla V100 (32GB VRAM)
*   CUDA: 11.8
*   cuDNN: 8.6


